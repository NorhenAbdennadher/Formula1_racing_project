Build a solution architecture for a data engineering solution using Azure Databricks, Azure Data Lake Gen2, Azure Data Factory and Power BI
• Creating and using Azure Databricks service and exploring the architecture of Databricks within Azure.
• Creating, configuring and monitoring Databricks clusters, cluster pools and jobs.
• Using Delta Lake to implement a solution using Lakehouse architecture.
• PySpark - Ingestion of CSV, simple and complex JSON files into the data lake as parquet files/ tables.
• PySpark - Transformations such as Filter, Join, Simple Aggregations, GroupBy, Window functions etc.
• PySpark - Creating local and temporary views.
• Spark SQL - Creating databases, tables and views.
• Spark SQL - Transformations such as Filter, Join, Simple Aggregations, GroupBy, Window functions etc.
• ADF - Creating pipelines to execute Databricks notebooks.
• ADF - Designing robust pipelines to deal with unexpected scenarios such as missing files.
• ADF - Scheduling the pipelines using data factory triggers to execute at regular intervals.
